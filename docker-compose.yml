services:
    text-generation-inference:
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities:
                              - gpu
        shm_size: '10g'
        volumes:
            - ~/.cache/huggingface/hub:/data
        ports:
            - 8080:80
        ipc: host
        image: ghcr.io/huggingface/text-generation-inference:2.2.0
        command: --model-id Equall/Saul-7B-Instruct-v1 --quantize bitsandbytes-nf4 --cuda-graphs 0
